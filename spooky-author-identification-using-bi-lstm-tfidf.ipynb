{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# I. Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/spooky-author-identification/test.zip\n",
      "/kaggle/input/spooky-author-identification/sample_submission.zip\n",
      "/kaggle/input/spooky-author-identification/train.zip\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.utils as ku\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (19579, 3)\n",
      "Validation data shape: (8392, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"/kaggle/input/spooky-author-identification/train.zip\")\n",
    "data_val = pd.read_csv(\"/kaggle/input/spooky-author-identification/test.zip\")\n",
    "\n",
    "print('Training data shape:',data_train.shape)\n",
    "print('Validation data shape:',data_val.shape)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# II. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>process however afforded means ascertaining di...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>never occurred fumbling might mere mistake</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>left hand gold snuff box capered hill cutting ...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>lovely spring looked windsor terrace sixteen f...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>finding nothing else even gold superintendent ...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  process however afforded means ascertaining di...    EAP\n",
       "1  id17569         never occurred fumbling might mere mistake    HPL\n",
       "2  id11008  left hand gold snuff box capered hill cutting ...    EAP\n",
       "3  id27763  lovely spring looked windsor terrace sixteen f...    MWS\n",
       "4  id12958  finding nothing else even gold superintendent ...    HPL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StopWords = set(stopwords.words('english'))\n",
    "\n",
    "def text_preprocess(text):\n",
    "    trans = str.maketrans('','',string.punctuation)\n",
    "    text = text.translate(trans)\n",
    "    text = ' '.join([word.lower() for word in text.split() if word.lower() not in StopWords])\n",
    "    return text\n",
    "\n",
    "data_train['text'] = data_train['text'].apply(text_preprocess)\n",
    "data_val['text'] = data_val['text'].apply(text_preprocess)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# III. Tokenization and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "X_train = data_train['text']\n",
    "X_train = X_train.tolist()\n",
    "X_test = data_val['text']\n",
    "X_test = X_test.tolist()\n",
    "y_train = data_train['author']\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_train_cat = ku.to_categorical(y_train, num_classes=3)\n",
    "val_id = data_val['id']\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "X_train_lemm = []\n",
    "for text in X_train:\n",
    "    lem_text = ''\n",
    "    for word in text.split():\n",
    "        lem_word = lemmatizer.lemmatize(word, pos='v')\n",
    "        lem_word = lemmatizer.lemmatize(lem_word)\n",
    "        lem_text = lem_text + ' ' + lem_word\n",
    "    X_train_lemm.append(lem_text)\n",
    "\n",
    "X_test_lemm = []\n",
    "for text in X_test:\n",
    "    lem_text = ''\n",
    "    for word in text.split():\n",
    "        lem_word = lemmatizer.lemmatize(word, pos='v')\n",
    "        lem_word = lemmatizer.lemmatize(lem_word)\n",
    "        lem_text = lem_text + ' ' + lem_word\n",
    "    X_test_lemm.append(lem_text)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_lemm)\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "max_len = 150\n",
    "train_seq = tokenizer.texts_to_sequences(X_train_lemm)\n",
    "train_pad = pad_sequences(train_seq, maxlen=max_len)\n",
    "test_seq = tokenizer.texts_to_sequences(X_test_lemm)\n",
    "test_pad = pad_sequences(test_seq, maxlen=max_len)\n",
    "\n",
    "label2idx = {\n",
    "    'EAP': 0,\n",
    "    'HPL': 1,\n",
    "    'MWS': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# IV. Training using TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,3), min_df=5, max_df=0.5)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_lemm)\n",
    "X_test_tfidf = tfidf.transform(X_test_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 ... 0 2 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.18965379, 0.51298162, 0.37707488, ..., 0.64167805, 0.26446662,\n",
       "       0.45248174])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000).fit(X_train_tfidf, y_train)\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "print(y_pred)\n",
    "output_prob = clf.predict_proba(X_test_tfidf)\n",
    "output_prob[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# V. Training using Bi-LSTM NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "39/39 [==============================] - 101s 3s/step - loss: 0.7352 - accuracy: 0.6651\n",
      "Epoch 2/20\n",
      "39/39 [==============================] - 98s 3s/step - loss: 0.3090 - accuracy: 0.8863\n",
      "Epoch 3/20\n",
      "39/39 [==============================] - 100s 3s/step - loss: 0.1901 - accuracy: 0.9305\n",
      "Epoch 4/20\n",
      "39/39 [==============================] - 98s 3s/step - loss: 0.1326 - accuracy: 0.9497\n",
      "Epoch 5/20\n",
      "39/39 [==============================] - 102s 3s/step - loss: 0.0963 - accuracy: 0.9637\n",
      "Epoch 6/20\n",
      "39/39 [==============================] - 99s 3s/step - loss: 0.0841 - accuracy: 0.9682\n",
      "Epoch 7/20\n",
      "39/39 [==============================] - 100s 3s/step - loss: 0.0759 - accuracy: 0.9713\n",
      "Epoch 8/20\n",
      "39/39 [==============================] - 101s 3s/step - loss: 0.0652 - accuracy: 0.9762\n",
      "Epoch 9/20\n",
      "39/39 [==============================] - 100s 3s/step - loss: 0.0557 - accuracy: 0.9791\n",
      "Epoch 10/20\n",
      "39/39 [==============================] - 100s 3s/step - loss: 0.0458 - accuracy: 0.9828\n",
      "Epoch 11/20\n",
      "39/39 [==============================] - 100s 3s/step - loss: 0.0428 - accuracy: 0.9844\n",
      "Epoch 12/20\n",
      "39/39 [==============================] - 100s 3s/step - loss: 0.0354 - accuracy: 0.9870\n",
      "Epoch 13/20\n",
      "39/39 [==============================] - 98s 3s/step - loss: 0.0295 - accuracy: 0.9891\n",
      "Epoch 14/20\n",
      "39/39 [==============================] - 99s 3s/step - loss: 0.0307 - accuracy: 0.9880\n",
      "Epoch 15/20\n",
      "39/39 [==============================] - 98s 3s/step - loss: 0.0299 - accuracy: 0.9890\n",
      "Epoch 16/20\n",
      "39/39 [==============================] - 100s 3s/step - loss: 0.0264 - accuracy: 0.9899\n",
      "Epoch 17/20\n",
      "39/39 [==============================] - 100s 3s/step - loss: 0.0264 - accuracy: 0.9904\n",
      "Epoch 18/20\n",
      "39/39 [==============================] - 100s 3s/step - loss: 0.0236 - accuracy: 0.9910\n",
      "Epoch 19/20\n",
      "39/39 [==============================] - 100s 3s/step - loss: 0.0275 - accuracy: 0.9899\n",
      "Epoch 20/20\n",
      "39/39 [==============================] - 100s 3s/step - loss: 0.0225 - accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size+1, 300, input_length=max_len),\n",
    "    keras.layers.SpatialDropout1D(0.5),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(32, dropout=0.3, recurrent_dropout=0.3)),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "history = model.fit(train_pad, y_train_cat, epochs=20, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 150, 300)          5430300   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 150, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 150, 128)          186880    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               19500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 903       \n",
      "=================================================================\n",
      "Total params: 5,678,799\n",
      "Trainable params: 5,678,799\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 0 ... 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn = model.predict_classes(test_pad)\n",
    "print(y_pred_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86144056]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cosine similarity between outputs from both methods.\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity([y_pred], [y_pred_nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission file.\n",
    "df = pd.DataFrame()\n",
    "df['id'] = val_id\n",
    "df['EAP'] = output_prob[:,0]\n",
    "df['HPL'] = output_prob[:,1]\n",
    "df['MWS'] = output_prob[:,2]\n",
    "\n",
    "df.to_csv('Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
